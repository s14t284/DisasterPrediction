{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keyword集約"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/1.train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20285\n",
      "272\n"
     ]
    }
   ],
   "source": [
    "def replace_rule(text):\n",
    "    words = text.split(\" \")\n",
    "    for i in range(len(words)):\n",
    "        words[i] = re.sub(r\"(する|した|の|犯|者|官|事態|証言)$\", \"\", words[i])\n",
    "        words[i] = re.sub(r\"\\S+テロ\", \"テロ\", words[i])\n",
    "        words[i] = re.sub(r\"\\S+雷\", \"雷\", words[i])\n",
    "        words[i] = re.sub(r\"\\S+衝突\", \"衝突\", words[i])\n",
    "        words[i] = re.sub(r\"\\S*殺人\\S*\", \"殺人\", words[i])\n",
    "    words = sorted(list(set(words)))\n",
    "    return \" \".join(words)\n",
    "    \n",
    "# 助詞やいらない部分を削除\n",
    "df['nkeyword'] = df.keyword.apply(replace_rule)\n",
    "nkeywords = df.nkeyword.to_list()\n",
    "print(len(nkeywords))\n",
    "print(len(set(nkeywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_keywords = df.nkeyword[df.nkeyword.apply(lambda x: len(x.split(\" \"))) == 1].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('怪我人', 206),\n",
       " ('消防', 203),\n",
       " ('サイレン', 202),\n",
       " ('感染', 200),\n",
       " ('震源地', 199),\n",
       " ('消防車', 199),\n",
       " ('窃盗', 199),\n",
       " ('盗撮', 135),\n",
       " ('暴力', 134),\n",
       " ('地滑り', 114)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(one_keywords))\n",
    "list(one_keywords.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      覚醒剤\n",
       "1        雷\n",
       "2       血液\n",
       "3    ハリケーン\n",
       "4       殺人\n",
       "5     土砂崩れ\n",
       "6       警察\n",
       "7     血まみれ\n",
       "8     自然災害\n",
       "9       死傷\n",
       "Name: topic_keyword, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decide_keyword(keywords: str):\n",
    "    keyword_list = keywords.split(\" \")\n",
    "    decided = keyword_list[0]\n",
    "    max_val = one_keywords[decided]\n",
    "    for k in keyword_list[1:]:\n",
    "        if max_val < one_keywords[k]:\n",
    "            decided = k\n",
    "            max_val = one_keywords[k]\n",
    "    return decided\n",
    "\n",
    "df['topic_keyword'] = df.nkeyword.apply(decide_keyword)\n",
    "df.topic_keyword.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_text_pairs = {}\n",
    "for k in one_keywords.keys():\n",
    "    topic_text_pairs[k] = df[df.topic_keyword == k].text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【マイリスト】カカカカ覚醒剤 https://t.co/15ZY9Oa2QS #sm36302050',\n",
       " '@noooooooorth @TGN54 覚醒剤初犯は無条件執行猶予ですよ。 初犯でも営利目的所持は、厳しいですよ。',\n",
       " '沢尻被告はベテランジャンキー？覚醒剤避けた可能性。・・そうなんだ。']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_text_pairs[\"覚醒剤\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['覚醒剤', '雷', '血液', ..., '爆発', '緊急', '炎上'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.concatenate([df.nkeyword.values,df.nkeyword.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
